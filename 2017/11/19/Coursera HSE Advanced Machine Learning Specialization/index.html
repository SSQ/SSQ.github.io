<!doctype html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>






<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.1" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Coursera,Machine Learning," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.1" />






<meta name="description" content="For quick searchingCourse can be found hereVideo in YouTubeLecture Slides can be found in my Github">
<meta name="keywords" content="Coursera,Machine Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Coursera HSE Advanced Machine Learning Specialization">
<meta property="og:url" content="https://ssq.github.io/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/index.html">
<meta property="og:site_name" content="SSQ">
<meta property="og:description" content="For quick searchingCourse can be found hereVideo in YouTubeLecture Slides can be found in my Github">
<meta property="og:updated_time" content="2017-12-04T10:43:02.237Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Coursera HSE Advanced Machine Learning Specialization">
<meta name="twitter:description" content="For quick searchingCourse can be found hereVideo in YouTubeLecture Slides can be found in my Github">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://ssq.github.io/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/"/>





  <title>Coursera HSE Advanced Machine Learning Specialization | SSQ</title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  




<script>
  (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
            (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
  })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');
  ga('create', 'UA-91307065-1', 'auto');
  ga('send', 'pageview');
</script>


  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?3c8ad2ecdd2387b44044b1d7cd3536a9";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>










  
  
    
  

  <div class="container sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">SSQ</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-friends">
          <a href="/friends" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-link"></i> <br />
            
            friends
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="Searching..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">
    <link itemprop="mainEntityOfPage" href="https://ssq.github.io/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="SSQ">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="SSQ">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Coursera HSE Advanced Machine Learning Specialization</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2017-11-19T09:39:07+08:00">
                2017-11-19
              </time>
            

            

            
          </span>

          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count disqus-comment-count"
                        data-disqus-identifier="2017/11/19/Coursera HSE Advanced Machine Learning Specialization/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          
             <span id="/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/" class="leancloud_visitors" data-flag-title="Coursera HSE Advanced Machine Learning Specialization">
               <span class="post-meta-divider">|</span>
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               
                 <span class="post-meta-item-text">Visitors </span>
               
                 <span class="leancloud-visitors-count"></span>
             </span>
          

          
            <span class="post-meta-divider">|</span>
            <span class="page-pv"><i class="fa fa-file-o"></i>
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          

          

        </div>
      </header>
    

    <div class="post-body" itemprop="articleBody">

      
      

      
        <div class="note primary"><p>For quick searching<br>Course can be found <a href="https://www.coursera.org/specializations/aml" target="_blank" rel="external">here</a><br>Video in <a href="">YouTube</a><br>Lecture Slides can be found in my Github</p>
</div>
<a id="more"></a>
<div class="note primary"><p><strong>About This Specialization</strong><br>This specialization gives an introduction to deep learning, reinforcement learning, natural language understanding, computer vision and Bayesian methods. Top Kaggle machine learning practitioners and CERN scientists will share their experience of solving real-world problems and help you to fill the gaps between theory and practice. Upon completion of 7 courses you will be able to apply modern machine learning methods in enterprise and understand the caveats of real-world data and settings.</p>
<p><strong>Projects Overview</strong><br>You will master your skills by solving a wide variety of real-world problems like image captioning and automatic game playing throughout the course projects. You will gain the hands-on experience of applying advanced machine learning techniques that provide the foundation to the current state-of-the art in AI.</p>
</div>
<h1 id="Introduction-to-Deep-Learning"><a href="#Introduction-to-Deep-Learning" class="headerlink" title="Introduction to Deep Learning"></a>Introduction to Deep Learning</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/intro-to-deep-learning" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
<p><strong>About this course:</strong> The goal of this course is to give learners basic understanding of modern neural networks and their applications in computer vision and natural language understanding. The course starts with a recap of linear models and discussion of stochastic optimization methods that are crucial for training deep neural networks. Learners will study all popular building blocks of neural networks including fully connected layers, convolutional and recurrent layers.<br>Learners will use these building blocks to define complex modern architectures in TensorFlow and Keras frameworks. In the course project learner will implement deep neural network for the task of image captioning which solves the problem of giving a text description for an input image.</p>
<p>The prerequisites for this course are:<br>1) Basic knowledge of Python.<br>2) Basic linear algebra and probability.</p>
<p>Please note that this is an advanced course and we assume basic knowledge of machine learning. You should understand:<br>1) Linear regression: mean squared error, analytical solution.<br>2) Logistic regression: model, cross-entropy loss, class probability estimation.<br>3) Gradient descent for linear models. Derivatives of MSE and cross-entropy loss functions.<br>4) The problem of overfitting.<br>5) Regularization for linear models.</p>
<p><strong>Who is this class for:</strong> Developers, analysts and researchers who are faced with tasks involving complex structure understanding such as image, sound and text analysis.</p>
</div>
<h2 id="Week-1-Introduction-to-optimization"><a href="#Week-1-Introduction-to-optimization" class="headerlink" title="Week 1 Introduction to optimization"></a>Week 1 Introduction to optimization</h2><div class="note primary"><p>Welcome to the “Introduction to Deep Learning” course! In the first week you’ll learn about linear models and stochatic optimization methods. Linear models are basic building blocks for many deep architectures, and stochastic optimization is used to learn every model that we’ll discuss in our course.</p>
</div>
<div class="note primary"><p><strong>Learning Objectives</strong></p>
<ul>
<li>Train a linear model for classification or regression task using stochastic gradient descent</li>
<li>Tune SGD optimization using different techniques</li>
<li>Apply regularization to train better models</li>
<li>Use linear models for classification and regression tasks</li>
</ul>
</div>
<h3 id="Course-intro"><a href="#Course-intro" class="headerlink" title="Course intro"></a>Course intro</h3><h4 id="Welcome-5-min"><a href="#Welcome-5-min" class="headerlink" title="Welcome!5 min"></a>Welcome!5 min</h4><h3 id="Linear-model-as-the-simplest-neural-network"><a href="#Linear-model-as-the-simplest-neural-network" class="headerlink" title="Linear model as the simplest neural network"></a>Linear model as the simplest neural network</h3><h4 id="Linear-regression-9-min"><a href="#Linear-regression-9-min" class="headerlink" title="Linear regression 9 min"></a>Linear regression 9 min</h4><h4 id="Linear-classification-10-min"><a href="#Linear-classification-10-min" class="headerlink" title="Linear classification 10 min"></a>Linear classification 10 min</h4><h4 id="Gradient-descent-5-min"><a href="#Gradient-descent-5-min" class="headerlink" title="Gradient descent 5 min"></a>Gradient descent 5 min</h4><h4 id="Quiz-Linear-models-3-questions"><a href="#Quiz-Linear-models-3-questions" class="headerlink" title="Quiz: Linear models 3 questions"></a>Quiz: Linear models 3 questions</h4><div class="note primary"><p>QUIZ<br>Linear models<br>3 questions<br>To Pass80% or higher<br>Attempts3 every 8 hours<br>Deadline<br>November 26, 11:59 PM PST</p>
</div>
<p>1 point<br>1.Consider a vector (1,−2,0.5). Apply a softmax transform to it and enter the first component (accurate to 2 decimal places).</p>
<p><input type="”text”" placeholder="0.60"><br><br><br>1 point<br>2.Suppose you are solving a 5-class classification problem with 10 features. How many parameters a linear model would have? Don’t forget bias terms!</p>
<p><input type="”text”" placeholder="55"><br><br><br>1 point<br>3.There is an analytical solution for linear regression parameters and MSE loss, but we usually prefer gradient descent optimization over it. What are the reasons?</p>
<p><input type="checkbox" disabled checked><label></label><br>Gradient descent is more scalable and can be applied for problems with high number of features</p>
<p><input type="checkbox" disabled><label></label><br>Gradient descent is a method developed especially for MSE loss</p>
<p><input type="checkbox" disabled><label></label><br>Gradient descent can find parameter values that give lower MSE value than parameters from analytical solution</p>
<p><input type="checkbox" disabled checked><label></label><br>Gradient descent doesn’t require to invert a matrix<br><br></p>
<h3 id="Regularization-in-machine-learning"><a href="#Regularization-in-machine-learning" class="headerlink" title="Regularization in machine learning"></a>Regularization in machine learning</h3><h4 id="Overfitting-problem-and-model-validation-6-min"><a href="#Overfitting-problem-and-model-validation-6-min" class="headerlink" title="Overfitting problem and model validation 6 min"></a>Overfitting problem and model validation 6 min</h4><h4 id="Model-regularization-5-min"><a href="#Model-regularization-5-min" class="headerlink" title="Model regularization 5 min"></a>Model regularization 5 min</h4><h4 id="Quiz-Overfitting-and-regularization-4-questions"><a href="#Quiz-Overfitting-and-regularization-4-questions" class="headerlink" title="Quiz: Overfitting and regularization 4 questions"></a>Quiz: Overfitting and regularization 4 questions</h4><div class="note primary"><p>QUIZ<br>Overfitting and regularization<br>4 questions<br>To Pass80% or higher<br>Attempts3 every 8 hours<br>Deadline<br>November 26, 11:59 PM PST</p>
</div>
<p>1 point<br>1.Select correct statements about overfitting:</p>
<p><input type="checkbox" disabled checked><label></label><br>Overfitting is a situation where a model gives lower quality for new data compared to quality on a training sample</p>
<p><input type="checkbox" disabled><label></label><br>Overfitting happens when model is too simple for the problem</p>
<p><input type="checkbox" disabled><label></label><br>Overfitting is a situation where a model gives comparable quality on new data and on a training sample</p>
<p><input type="checkbox" disabled checked><label></label><br>Large model weights can indicate that model is overfitted<br><br><br>1 point<br>2.What disadvantages do model validation on holdout sample have?</p>
<p><input type="checkbox" disabled><label></label><br>It requires multiple model fitting</p>
<p><input type="checkbox" disabled checked><label></label><br>It is sensitive to the particular split of the sample into training and test parts</p>
<p><input type="checkbox" disabled checked><label></label><br>It can give biased quality estimates for small samples<br><br><br><div class="note primary"><p>123,1,13,|3,12,2|23</p>
</div><br>1 point<br>3.Suppose you are using k-fold cross-validation to assess model quality. How many times should you train the model during this procedure?</p>
<p><input type="radio" disabled><label></label><br>1</p>
<p><input type="radio" disabled checked><label></label><br>k</p>
<p><input type="radio" disabled><label></label><br>k(k−1)/2</p>
<p><input type="radio" disabled><label></label><br>k2<br><br><br>1 point<br>4.Select correct statements about regularization:</p>
<p><input type="checkbox" disabled><label></label><br>Weight penalty reduces the number of model parameters and leads to faster model training</p>
<p><input type="checkbox" disabled><label></label><br>Reducing the training sample size makes data simpler and then leads to better quality</p>
<p><input type="checkbox" disabled checked><label></label><br>Regularization restricts model complexity (namely the scale of the coefficients) to reduce overfitting</p>
<p><input type="checkbox" disabled checked><label></label><br>Weight penalty drives model parameters closer to zero and prevents the model from being too sensitive to small changes in features<br><br></p>
<h3 id="Stochastic-methods-for-optimization"><a href="#Stochastic-methods-for-optimization" class="headerlink" title="Stochastic methods for optimization"></a>Stochastic methods for optimization</h3><h4 id="Stochastic-gradient-descent-5-min"><a href="#Stochastic-gradient-descent-5-min" class="headerlink" title="Stochastic gradient descent 5 min"></a>Stochastic gradient descent 5 min</h4><h4 id="Gradient-descent-extensions-9-min"><a href="#Gradient-descent-extensions-9-min" class="headerlink" title="Gradient descent extensions 9 min"></a>Gradient descent extensions 9 min</h4><h4 id="Linear-models-and-optimization"><a href="#Linear-models-and-optimization" class="headerlink" title="Linear models and optimization"></a>Linear models and optimization</h4><h4 id="Programming-Assignment-Linear-models-and-optimization-3h"><a href="#Programming-Assignment-Linear-models-and-optimization-3h" class="headerlink" title="Programming Assignment: Linear models and optimization 3h"></a>Programming Assignment: Linear models and optimization 3h</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><div class="line">1</div><div class="line">2</div><div class="line">3</div><div class="line">4</div><div class="line">5</div><div class="line">6</div><div class="line">7</div><div class="line">8</div><div class="line">9</div><div class="line">10</div><div class="line">11</div><div class="line">12</div><div class="line">13</div><div class="line">14</div><div class="line">15</div><div class="line">16</div><div class="line">17</div><div class="line">18</div><div class="line">19</div><div class="line">20</div><div class="line">21</div><div class="line">22</div><div class="line">23</div><div class="line">24</div><div class="line">25</div><div class="line">26</div><div class="line">27</div><div class="line">28</div><div class="line">29</div><div class="line">30</div><div class="line">31</div><div class="line">32</div><div class="line">33</div><div class="line">34</div><div class="line">35</div><div class="line">36</div><div class="line">37</div><div class="line">38</div><div class="line">39</div><div class="line">40</div><div class="line">41</div><div class="line">42</div><div class="line">43</div><div class="line">44</div><div class="line">45</div><div class="line">46</div><div class="line">47</div><div class="line">48</div><div class="line">49</div><div class="line">50</div><div class="line">51</div><div class="line">52</div><div class="line">53</div><div class="line">54</div><div class="line">55</div><div class="line">56</div><div class="line">57</div><div class="line">58</div><div class="line">59</div><div class="line">60</div><div class="line">61</div><div class="line">62</div><div class="line">63</div><div class="line">64</div><div class="line">65</div><div class="line">66</div><div class="line">67</div><div class="line">68</div><div class="line">69</div><div class="line">70</div><div class="line">71</div><div class="line">72</div><div class="line">73</div><div class="line">74</div><div class="line">75</div><div class="line">76</div><div class="line">77</div><div class="line">78</div><div class="line">79</div><div class="line">80</div><div class="line">81</div><div class="line">82</div><div class="line">83</div><div class="line">84</div><div class="line">85</div><div class="line">86</div><div class="line">87</div><div class="line">88</div><div class="line">89</div><div class="line">90</div><div class="line">91</div><div class="line">92</div><div class="line">93</div><div class="line">94</div><div class="line">95</div><div class="line">96</div><div class="line">97</div><div class="line">98</div><div class="line">99</div><div class="line">100</div><div class="line">101</div><div class="line">102</div><div class="line">103</div><div class="line">104</div><div class="line">105</div><div class="line">106</div><div class="line">107</div><div class="line">108</div><div class="line">109</div><div class="line">110</div><div class="line">111</div><div class="line">112</div><div class="line">113</div><div class="line">114</div><div class="line">115</div><div class="line">116</div><div class="line">117</div><div class="line">118</div><div class="line">119</div><div class="line">120</div><div class="line">121</div><div class="line">122</div><div class="line">123</div><div class="line">124</div><div class="line">125</div><div class="line">126</div><div class="line">127</div><div class="line">128</div><div class="line">129</div><div class="line">130</div><div class="line">131</div><div class="line">132</div><div class="line">133</div><div class="line">134</div><div class="line">135</div><div class="line">136</div><div class="line">137</div><div class="line">138</div><div class="line">139</div><div class="line">140</div><div class="line">141</div><div class="line">142</div><div class="line">143</div><div class="line">144</div><div class="line">145</div><div class="line">146</div><div class="line">147</div><div class="line">148</div><div class="line">149</div><div class="line">150</div><div class="line">151</div><div class="line">152</div><div class="line">153</div><div class="line">154</div><div class="line">155</div><div class="line">156</div><div class="line">157</div><div class="line">158</div><div class="line">159</div><div class="line">160</div><div class="line">161</div><div class="line">162</div><div class="line">163</div><div class="line">164</div><div class="line">165</div><div class="line">166</div><div class="line">167</div><div class="line">168</div><div class="line">169</div><div class="line">170</div><div class="line">171</div><div class="line">172</div><div class="line">173</div><div class="line">174</div><div class="line">175</div><div class="line">176</div><div class="line">177</div><div class="line">178</div><div class="line">179</div><div class="line">180</div><div class="line">181</div><div class="line">182</div><div class="line">183</div><div class="line">184</div><div class="line">185</div><div class="line">186</div><div class="line">187</div><div class="line">188</div><div class="line">189</div><div class="line">190</div><div class="line">191</div><div class="line">192</div><div class="line">193</div><div class="line">194</div><div class="line">195</div><div class="line">196</div><div class="line">197</div><div class="line">198</div><div class="line">199</div><div class="line">200</div><div class="line">201</div><div class="line">202</div><div class="line">203</div><div class="line">204</div><div class="line">205</div><div class="line">206</div><div class="line">207</div><div class="line">208</div><div class="line">209</div><div class="line">210</div><div class="line">211</div><div class="line">212</div><div class="line">213</div><div class="line">214</div><div class="line">215</div><div class="line">216</div><div class="line">217</div><div class="line">218</div><div class="line">219</div><div class="line">220</div><div class="line">221</div><div class="line">222</div><div class="line">223</div><div class="line">224</div><div class="line">225</div><div class="line">226</div><div class="line">227</div><div class="line">228</div><div class="line">229</div><div class="line">230</div><div class="line">231</div><div class="line">232</div><div class="line">233</div><div class="line">234</div><div class="line">235</div><div class="line">236</div><div class="line">237</div><div class="line">238</div><div class="line">239</div><div class="line">240</div><div class="line">241</div><div class="line">242</div><div class="line">243</div><div class="line">244</div><div class="line">245</div><div class="line">246</div><div class="line">247</div><div class="line">248</div><div class="line">249</div><div class="line">250</div><div class="line">251</div><div class="line">252</div><div class="line">253</div><div class="line">254</div><div class="line">255</div><div class="line">256</div><div class="line">257</div><div class="line">258</div><div class="line">259</div><div class="line">260</div><div class="line">261</div><div class="line">262</div><div class="line">263</div><div class="line">264</div><div class="line">265</div><div class="line">266</div><div class="line">267</div><div class="line">268</div><div class="line">269</div><div class="line">270</div><div class="line">271</div><div class="line">272</div><div class="line">273</div><div class="line">274</div><div class="line">275</div><div class="line">276</div><div class="line">277</div><div class="line">278</div><div class="line">279</div><div class="line">280</div><div class="line">281</div><div class="line">282</div><div class="line">283</div><div class="line">284</div><div class="line">285</div><div class="line">286</div><div class="line">287</div><div class="line">288</div><div class="line">289</div><div class="line">290</div><div class="line">291</div><div class="line">292</div><div class="line">293</div><div class="line">294</div><div class="line">295</div><div class="line">296</div><div class="line">297</div><div class="line">298</div><div class="line">299</div><div class="line">300</div><div class="line">301</div><div class="line">302</div><div class="line">303</div><div class="line">304</div><div class="line">305</div><div class="line">306</div><div class="line">307</div><div class="line">308</div><div class="line">309</div><div class="line">310</div><div class="line">311</div><div class="line">312</div><div class="line">313</div><div class="line">314</div><div class="line">315</div><div class="line">316</div><div class="line">317</div><div class="line">318</div><div class="line">319</div><div class="line">320</div><div class="line">321</div><div class="line">322</div><div class="line">323</div><div class="line">324</div><div class="line">325</div><div class="line">326</div><div class="line">327</div><div class="line">328</div><div class="line">329</div><div class="line">330</div><div class="line">331</div><div class="line">332</div><div class="line">333</div><div class="line">334</div><div class="line">335</div><div class="line">336</div><div class="line">337</div><div class="line">338</div><div class="line">339</div><div class="line">340</div><div class="line">341</div><div class="line">342</div><div class="line">343</div><div class="line">344</div><div class="line">345</div><div class="line">346</div><div class="line">347</div><div class="line">348</div><div class="line">349</div><div class="line">350</div><div class="line">351</div><div class="line">352</div><div class="line">353</div><div class="line">354</div><div class="line">355</div><div class="line">356</div><div class="line">357</div><div class="line">358</div><div class="line">359</div><div class="line">360</div><div class="line">361</div><div class="line">362</div><div class="line">363</div><div class="line">364</div><div class="line">365</div><div class="line">366</div><div class="line">367</div><div class="line">368</div><div class="line">369</div><div class="line">370</div><div class="line">371</div><div class="line">372</div><div class="line">373</div><div class="line">374</div><div class="line">375</div><div class="line">376</div><div class="line">377</div><div class="line">378</div><div class="line">379</div><div class="line">380</div><div class="line">381</div><div class="line">382</div><div class="line">383</div><div class="line">384</div><div class="line">385</div><div class="line">386</div><div class="line">387</div><div class="line">388</div><div class="line">389</div><div class="line">390</div><div class="line">391</div><div class="line">392</div><div class="line">393</div><div class="line">394</div><div class="line">395</div><div class="line">396</div><div class="line">397</div><div class="line">398</div><div class="line">399</div><div class="line">400</div><div class="line">401</div><div class="line">402</div><div class="line">403</div><div class="line">404</div><div class="line">405</div><div class="line">406</div><div class="line">407</div><div class="line">408</div><div class="line">409</div><div class="line">410</div><div class="line">411</div><div class="line">412</div><div class="line">413</div><div class="line">414</div><div class="line">415</div><div class="line">416</div><div class="line">417</div><div class="line">418</div><div class="line">419</div><div class="line">420</div><div class="line">421</div><div class="line">422</div><div class="line">423</div><div class="line">424</div><div class="line">425</div><div class="line">426</div><div class="line">427</div><div class="line">428</div><div class="line">429</div><div class="line">430</div><div class="line">431</div><div class="line">432</div><div class="line">433</div><div class="line">434</div><div class="line">435</div><div class="line">436</div><div class="line">437</div><div class="line">438</div><div class="line">439</div><div class="line">440</div><div class="line">441</div><div class="line">442</div><div class="line">443</div><div class="line">444</div><div class="line">445</div><div class="line">446</div><div class="line">447</div><div class="line">448</div><div class="line">449</div><div class="line">450</div><div class="line">451</div><div class="line">452</div><div class="line">453</div><div class="line">454</div><div class="line">455</div><div class="line">456</div><div class="line">457</div><div class="line">458</div><div class="line">459</div><div class="line">460</div><div class="line">461</div><div class="line">462</div><div class="line">463</div><div class="line">464</div><div class="line">465</div><div class="line">466</div><div class="line">467</div><div class="line">468</div><div class="line">469</div><div class="line">470</div><div class="line">471</div><div class="line">472</div><div class="line">473</div><div class="line">474</div><div class="line">475</div><div class="line">476</div><div class="line">477</div><div class="line">478</div><div class="line">479</div><div class="line">480</div><div class="line">481</div><div class="line">482</div><div class="line">483</div><div class="line">484</div><div class="line">485</div><div class="line">486</div><div class="line">487</div></pre></td><td class="code"><pre><div class="line"></div><div class="line"><span class="comment"># coding: utf-8</span></div><div class="line"></div><div class="line"><span class="comment"># # Programming assignment (Linear models, Optimization)</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># In this programming assignment you will implement a linear classifier and train it using stochastic gradient descent modifications and numpy.</span></div><div class="line"></div><div class="line"><span class="comment"># In[1]:</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</div><div class="line">get_ipython().magic(<span class="string">'matplotlib inline'</span>)</div><div class="line"><span class="keyword">import</span> matplotlib.pyplot <span class="keyword">as</span> plt</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[2]:</span></div><div class="line"></div><div class="line"><span class="keyword">import</span> sys</div><div class="line">sys.path.append(<span class="string">".."</span>)</div><div class="line"><span class="keyword">import</span> grading</div><div class="line">grader = grading.Grader(assignment_key=<span class="string">"UaHtvpEFEee0XQ6wjK-hZg"</span>, </div><div class="line">                      all_parts=[<span class="string">"xU7U4"</span>, <span class="string">"HyTF6"</span>, <span class="string">"uNidL"</span>, <span class="string">"ToK7N"</span>, <span class="string">"GBdgZ"</span>, <span class="string">"dLdHG"</span>])</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[3]:</span></div><div class="line"></div><div class="line"><span class="comment"># token expires every 30 min</span></div><div class="line">COURSERA_TOKEN = <span class="string">""</span></div><div class="line">COURSERA_EMAIL = <span class="string">""</span></div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ## Two-dimensional classification</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># To make things more intuitive, let's solve a 2D classification problem with synthetic data.</span></div><div class="line"></div><div class="line"><span class="comment"># In[4]:</span></div><div class="line"></div><div class="line"><span class="keyword">with</span> open(<span class="string">'train.npy'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> fin:</div><div class="line">    X = np.load(fin)</div><div class="line">    </div><div class="line"><span class="keyword">with</span> open(<span class="string">'target.npy'</span>, <span class="string">'rb'</span>) <span class="keyword">as</span> fin:</div><div class="line">    y = np.load(fin)</div><div class="line"></div><div class="line">plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired, s=<span class="number">20</span>)</div><div class="line">plt.show()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[5]:</span></div><div class="line"></div><div class="line">print(X.shape)</div><div class="line">print(y.shape)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># # Task</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># ## Features</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># As you can notice the data above isn't linearly separable. Since that we should add features (or use non-linear model). Note that decision line between two classes have form of circle, since that we can add quadratic features to make the problem linearly separable. The idea under this displayed on image below:</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># ![](kernel.png)</span></div><div class="line"></div><div class="line"><span class="comment"># In[6]:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">expand</span><span class="params">(X)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Adds quadratic features. </div><div class="line">    This expansion allows your linear model to make non-linear separation.</div><div class="line">    </div><div class="line">    For each sample (row in matrix), compute an expanded row:</div><div class="line">    [feature0, feature1, feature0^2, feature1^2, feature1*feature2, 1]</div><div class="line">    </div><div class="line">    :param X: matrix of features, shape [n_samples,2]</div><div class="line">    :returns: expanded features of shape [n_samples,6]</div><div class="line">    """</div><div class="line">    X_expanded = np.zeros((X.shape[<span class="number">0</span>], <span class="number">6</span>))</div><div class="line">    </div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;</span></div><div class="line">    X_expanded[:,<span class="number">0</span>], X_expanded[:,<span class="number">1</span>] = X[:,<span class="number">0</span>],X[:,<span class="number">1</span>]</div><div class="line">    X_expanded[:,<span class="number">2</span>], X_expanded[:,<span class="number">3</span>]= X[:,<span class="number">0</span>]**<span class="number">2</span>, X[:,<span class="number">1</span>]**<span class="number">2</span></div><div class="line">    X_expanded[:,<span class="number">4</span>], X_expanded[:,<span class="number">5</span>] = X[:,<span class="number">0</span>]*X[:,<span class="number">1</span>], np.ones(X.shape[<span class="number">0</span>])</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> X_expanded</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[7]:</span></div><div class="line"></div><div class="line">X_expanded = expand(X)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Here are some tests for your implementation of `expand` function.</span></div><div class="line"></div><div class="line"><span class="comment"># In[8]:</span></div><div class="line"></div><div class="line"><span class="comment"># simple test on random numbers</span></div><div class="line"></div><div class="line">dummy_X = np.array([</div><div class="line">        [<span class="number">0</span>,<span class="number">0</span>],</div><div class="line">        [<span class="number">1</span>,<span class="number">0</span>],</div><div class="line">        [<span class="number">2.61</span>,<span class="number">-1.28</span>],</div><div class="line">        [<span class="number">-0.59</span>,<span class="number">2.1</span>]</div><div class="line">    ])</div><div class="line"></div><div class="line"><span class="comment"># call your expand function</span></div><div class="line">dummy_expanded = expand(dummy_X)</div><div class="line"></div><div class="line"><span class="comment"># what it should have returned:   x0       x1       x0^2     x1^2     x0*x1    1</span></div><div class="line">dummy_expanded_ans = np.array([[ <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">1.</span>    ],</div><div class="line">                               [ <span class="number">1.</span>    ,  <span class="number">0.</span>    ,  <span class="number">1.</span>    ,  <span class="number">0.</span>    ,  <span class="number">0.</span>    ,  <span class="number">1.</span>    ],</div><div class="line">                               [ <span class="number">2.61</span>  , <span class="number">-1.28</span>  ,  <span class="number">6.8121</span>,  <span class="number">1.6384</span>, <span class="number">-3.3408</span>,  <span class="number">1.</span>    ],</div><div class="line">                               [<span class="number">-0.59</span>  ,  <span class="number">2.1</span>   ,  <span class="number">0.3481</span>,  <span class="number">4.41</span>  , <span class="number">-1.239</span> ,  <span class="number">1.</span>    ]])</div><div class="line"></div><div class="line"><span class="comment">#tests</span></div><div class="line"><span class="keyword">assert</span> isinstance(dummy_expanded,np.ndarray), <span class="string">"please make sure you return numpy array"</span></div><div class="line"><span class="keyword">assert</span> dummy_expanded.shape == dummy_expanded_ans.shape, <span class="string">"please make sure your shape is correct"</span></div><div class="line"><span class="keyword">assert</span> np.allclose(dummy_expanded,dummy_expanded_ans,<span class="number">1e-3</span>), <span class="string">"Something's out of order with features"</span></div><div class="line"></div><div class="line">print(<span class="string">"Seems legit!"</span>)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ## Logistic regression</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># To classify objects we will obtain probability of object belongs to class '1'. To predict probability we will use output of linear model and logistic function:</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># $$ a(x; w) = \langle w, x \rangle $$</span></div><div class="line"><span class="comment"># $$ P( y=1 \; \big| \; x, \, w) = \dfrac&#123;1&#125;&#123;1 + \exp(- \langle w, x \rangle)&#125; = \sigma(\langle w, x \rangle)$$</span></div><div class="line"><span class="comment"># </span></div><div class="line"></div><div class="line"><span class="comment"># In[9]:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">probability</span><span class="params">(X, w)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Given input features and weights</div><div class="line">    return predicted probabilities of y==1 given x, P(y=1|x), see description above</div><div class="line">        </div><div class="line">    Don't forget to use expand(X) function (where necessary) in this and subsequent functions.</div><div class="line">    </div><div class="line">    :param X: feature matrix X of shape [n_samples,6] (expanded)</div><div class="line">    :param w: weight vector w of shape [6] for each of the expanded features</div><div class="line">    :returns: an array of predicted probabilities in [0,1] interval.</div><div class="line">    """</div><div class="line"></div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;</span></div><div class="line">    z = np.dot(X,w)</div><div class="line">    </div><div class="line">    a = <span class="number">1.</span>/(<span class="number">1</span>+np.exp(-z))</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> np.array(a)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[10]:</span></div><div class="line"></div><div class="line">dummy_weights = np.linspace(<span class="number">-1</span>, <span class="number">1</span>, <span class="number">6</span>)</div><div class="line">ans_part1 = probability(X_expanded[:<span class="number">1</span>, :], dummy_weights)[<span class="number">0</span>]</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[11]:</span></div><div class="line"></div><div class="line">print(ans_part1)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[12]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"xU7U4"</span>, ans_part1)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[13]:</span></div><div class="line"></div><div class="line"><span class="comment"># you can make submission with answers so far to check yourself at this stage</span></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In logistic regression the optimal parameters $w$ are found by cross-entropy minimization:</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># $$ L(w) =  - &#123;1 \over \ell&#125; \sum_&#123;i=1&#125;^\ell \left[ &#123;y_i \cdot log P(y_i \, | \, x_i,w) + (1-y_i) \cdot log (1-P(y_i\, | \, x_i,w))&#125;\right] $$</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># </span></div><div class="line"></div><div class="line"><span class="comment"># In[14]:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_loss</span><span class="params">(X, y, w)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Given feature matrix X [n_samples,6], target vector [n_samples] of 1/0,</div><div class="line">    and weight vector w [6], compute scalar loss function using formula above.</div><div class="line">    """</div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;</span></div><div class="line">    l = X.shape[<span class="number">0</span>]</div><div class="line">    </div><div class="line">    a = probability(X, w)</div><div class="line">    </div><div class="line">    cross_entropy = y*np.log(a) +(<span class="number">1</span>-y)*np.log(<span class="number">1</span>-a)</div><div class="line">    cost = -np.sum(cross_entropy)/float(l)</div><div class="line">    </div><div class="line">    cost = np.squeeze(cost)      <span class="comment"># To make sure your cost's shape is what we expect (e.g. this turns [[17]] into 17).</span></div><div class="line">    <span class="keyword">assert</span>(cost.shape == ())</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> cost</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[15]:</span></div><div class="line"></div><div class="line"><span class="comment"># use output of this cell to fill answer field </span></div><div class="line">ans_part2 = compute_loss(X_expanded, y, dummy_weights)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[16]:</span></div><div class="line"></div><div class="line">print(ans_part2)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[17]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"HyTF6"</span>, ans_part2)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[18]:</span></div><div class="line"></div><div class="line"><span class="comment"># you can make submission with answers so far to check yourself at this stage</span></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Since we train our model with gradient descent, we should compute gradients.</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># To be specific, we need a derivative of loss function over each weight [6 of them].</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># $$ \nabla_w L = ...$$</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># We won't be giving you the exact formula this time — instead, try figuring out a derivative with pen and paper. </span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># As usual, we've made a small test for you, but if you need more, feel free to check your math against finite differences (estimate how $L$ changes if you shift $w$ by $10^&#123;-5&#125;$ or so).</span></div><div class="line"></div><div class="line"><span class="comment"># In[19]:</span></div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">compute_grad</span><span class="params">(X, y, w)</span>:</span></div><div class="line">    <span class="string">"""</span></div><div class="line">    Given feature matrix X [n_samples,6], target vector [n_samples] of 1/0,</div><div class="line">    and weight vector w [6], compute vector [6] of derivatives of L over each weights.</div><div class="line">    """</div><div class="line">    </div><div class="line">    <span class="comment"># TODO&lt;your code here&gt;</span></div><div class="line">    m = X.shape[<span class="number">0</span>]</div><div class="line">    A = probability(X, w)</div><div class="line">    dZ = A - y</div><div class="line">    <span class="comment">#cost = compute_loss(X, y, w)</span></div><div class="line">    dW = np.dot(dZ, X) / float(m)</div><div class="line">    </div><div class="line">    <span class="keyword">return</span> dW</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[20]:</span></div><div class="line"></div><div class="line"><span class="comment"># use output of this cell to fill answer field </span></div><div class="line">ans_part3 = np.linalg.norm(compute_grad(X_expanded, y, dummy_weights))</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[21]:</span></div><div class="line"></div><div class="line">print(ans_part3)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[22]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"uNidL"</span>, ans_part3)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[23]:</span></div><div class="line"></div><div class="line"><span class="comment"># you can make submission with answers so far to check yourself at this stage</span></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># Here's an auxiliary function that visualizes the predictions:</span></div><div class="line"></div><div class="line"><span class="comment"># In[24]:</span></div><div class="line"></div><div class="line"><span class="keyword">from</span> IPython <span class="keyword">import</span> display</div><div class="line"></div><div class="line">h = <span class="number">0.01</span></div><div class="line">x_min, x_max = X[:, <span class="number">0</span>].min() - <span class="number">1</span>, X[:, <span class="number">0</span>].max() + <span class="number">1</span></div><div class="line">y_min, y_max = X[:, <span class="number">1</span>].min() - <span class="number">1</span>, X[:, <span class="number">1</span>].max() + <span class="number">1</span></div><div class="line">xx, yy = np.meshgrid(np.arange(x_min, x_max, h), np.arange(y_min, y_max, h))</div><div class="line"></div><div class="line"><span class="function"><span class="keyword">def</span> <span class="title">visualize</span><span class="params">(X, y, w, history)</span>:</span></div><div class="line">    <span class="string">"""draws classifier prediction with matplotlib magic"""</span></div><div class="line">    Z = probability(expand(np.c_[xx.ravel(), yy.ravel()]), w)</div><div class="line">    Z = Z.reshape(xx.shape)</div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>)</div><div class="line">    plt.contourf(xx, yy, Z, alpha=<span class="number">0.8</span>)</div><div class="line">    plt.scatter(X[:, <span class="number">0</span>], X[:, <span class="number">1</span>], c=y, cmap=plt.cm.Paired)</div><div class="line">    plt.xlim(xx.min(), xx.max())</div><div class="line">    plt.ylim(yy.min(), yy.max())</div><div class="line">    </div><div class="line">    plt.subplot(<span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>)</div><div class="line">    plt.plot(history)</div><div class="line">    plt.grid()</div><div class="line">    ymin, ymax = plt.ylim()</div><div class="line">    plt.ylim(<span class="number">0</span>, ymax)</div><div class="line">    display.clear_output(wait=<span class="keyword">True</span>)</div><div class="line">    plt.show()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[25]:</span></div><div class="line"></div><div class="line">visualize(X, y, dummy_weights, [<span class="number">0.5</span>, <span class="number">0.5</span>, <span class="number">0.25</span>])</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ## Training</span></div><div class="line"><span class="comment"># In this section we'll use the functions you wrote to train our classifier using stochastic gradient descent.</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># You can try change hyperparameters like batch size, learning rate and so on to find the best one, but use our hyperparameters when fill answers.</span></div><div class="line"></div><div class="line"><span class="comment"># ## Mini-batch SGD</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># Stochastic gradient descent just takes a random example on each iteration, calculates a gradient of the loss on it and makes a step:</span></div><div class="line"><span class="comment"># $$ w_t = w_&#123;t-1&#125; - \eta \dfrac&#123;1&#125;&#123;m&#125; \sum_&#123;j=1&#125;^m \nabla_w L(w_t, x_&#123;i_j&#125;, y_&#123;i_j&#125;) $$</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># </span></div><div class="line"></div><div class="line"><span class="comment"># In[26]:</span></div><div class="line"></div><div class="line"><span class="comment"># please use np.random.seed(42), eta=0.1, n_iter=100 and batch_size=4 for deterministic results</span></div><div class="line"></div><div class="line">np.random.seed(<span class="number">42</span>)</div><div class="line">w = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</div><div class="line"></div><div class="line">eta= <span class="number">0.1</span> <span class="comment"># learning rate</span></div><div class="line"></div><div class="line">n_iter = <span class="number">100</span></div><div class="line">batch_size = <span class="number">4</span></div><div class="line">loss = np.zeros(n_iter)</div><div class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_iter):</div><div class="line">    ind = np.random.choice(X_expanded.shape[<span class="number">0</span>], batch_size)</div><div class="line">    loss[i] = compute_loss(X_expanded, y, w)</div><div class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</div><div class="line">        visualize(X_expanded[ind, :], y[ind], w, loss)</div><div class="line"></div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;    </span></div><div class="line">    dW = compute_grad(X_expanded[ind, :], y[ind], w)</div><div class="line">    w = w - eta * dW </div><div class="line">visualize(X, y, w, loss)</div><div class="line">plt.clf()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[27]:</span></div><div class="line"></div><div class="line"><span class="comment"># use output of this cell to fill answer field </span></div><div class="line"></div><div class="line">ans_part4 = compute_loss(X_expanded, y, w)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[28]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"ToK7N"</span>, ans_part4)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[29]:</span></div><div class="line"></div><div class="line"><span class="comment"># you can make submission with answers so far to check yourself at this stage</span></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ## SGD with momentum</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># Momentum is a method that helps accelerate SGD in the relevant direction and dampens oscillations as can be seen in image below. It does this by adding a fraction $\alpha$ of the update vector of the past time step to the current update vector.</span></div><div class="line"><span class="comment"># &lt;br&gt;</span></div><div class="line"><span class="comment"># &lt;br&gt;</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># $$ \nu_t = \alpha \nu_&#123;t-1&#125; + \eta\dfrac&#123;1&#125;&#123;m&#125; \sum_&#123;j=1&#125;^m \nabla_w L(w_t, x_&#123;i_j&#125;, y_&#123;i_j&#125;) $$</span></div><div class="line"><span class="comment"># $$ w_t = w_&#123;t-1&#125; - \nu_t$$</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># &lt;br&gt;</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># ![](sgd.png)</span></div><div class="line"><span class="comment"># </span></div><div class="line"></div><div class="line"><span class="comment"># In[30]:</span></div><div class="line"></div><div class="line"><span class="comment"># please use np.random.seed(42), eta=0.05, alpha=0.9, n_iter=100 and batch_size=4 for deterministic results</span></div><div class="line">np.random.seed(<span class="number">42</span>)</div><div class="line">w = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1</span>])</div><div class="line"></div><div class="line">eta = <span class="number">0.05</span> <span class="comment"># learning rate</span></div><div class="line">alpha = <span class="number">0.9</span> <span class="comment"># momentum</span></div><div class="line">nu = np.zeros_like(w)</div><div class="line"></div><div class="line">n_iter = <span class="number">100</span></div><div class="line">batch_size = <span class="number">4</span></div><div class="line">loss = np.zeros(n_iter)</div><div class="line">plt.figure(figsize=(<span class="number">12</span>, <span class="number">5</span>))</div><div class="line"></div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_iter):</div><div class="line">    ind = np.random.choice(X_expanded.shape[<span class="number">0</span>], batch_size)</div><div class="line">    loss[i] = compute_loss(X_expanded, y, w)</div><div class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</div><div class="line">        visualize(X_expanded[ind, :], y[ind], w, loss)</div><div class="line"></div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;</span></div><div class="line">    dW = compute_grad(X_expanded[ind, :], y[ind], w)</div><div class="line">    nu = alpha*nu+eta*dW</div><div class="line">    w = w - nu</div><div class="line">visualize(X, y, w, loss)</div><div class="line">plt.clf()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[31]:</span></div><div class="line"></div><div class="line"><span class="comment"># use output of this cell to fill answer field </span></div><div class="line"></div><div class="line">ans_part5 = compute_loss(X_expanded, y, w)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[32]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"GBdgZ"</span>, ans_part5)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[33]:</span></div><div class="line"></div><div class="line"><span class="comment"># you can make submission with answers so far to check yourself at this stage</span></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># ## RMSprop</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># Implement RMSPROP algorithm, which use squared gradients to adjust learning rate:</span></div><div class="line"><span class="comment"># </span></div><div class="line"><span class="comment"># $$ G_j^t = \alpha G_j^&#123;t-1&#125; + (1 - \alpha) g_&#123;tj&#125;^2 $$</span></div><div class="line"><span class="comment"># $$ w_j^t = w_j^&#123;t-1&#125; - \dfrac&#123;\eta&#125;&#123;\sqrt&#123;G_j^t + \varepsilon&#125;&#125; g_&#123;tj&#125; $$</span></div><div class="line"></div><div class="line"><span class="comment"># In[34]:</span></div><div class="line"></div><div class="line"><span class="comment"># please use np.random.seed(42), eta=0.1, alpha=0.9, n_iter=100 and batch_size=4 for deterministic results</span></div><div class="line">np.random.seed(<span class="number">42</span>)</div><div class="line"></div><div class="line">w = np.array([<span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">0</span>, <span class="number">1.</span>])</div><div class="line"></div><div class="line">eta = <span class="number">0.1</span> <span class="comment"># learning rate</span></div><div class="line">alpha = <span class="number">0.9</span> <span class="comment"># moving average of gradient norm squared</span></div><div class="line">G = np.zeros_like(w)</div><div class="line">g2 = np.zeros_like(w)</div><div class="line">eps = <span class="number">1e-8</span></div><div class="line"></div><div class="line">n_iter = <span class="number">100</span></div><div class="line">batch_size = <span class="number">4</span></div><div class="line">loss = np.zeros(n_iter)</div><div class="line">plt.figure(figsize=(<span class="number">12</span>,<span class="number">5</span>))</div><div class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(n_iter):</div><div class="line">    ind = np.random.choice(X_expanded.shape[<span class="number">0</span>], batch_size)</div><div class="line">    loss[i] = compute_loss(X_expanded, y, w)</div><div class="line">    <span class="keyword">if</span> i % <span class="number">10</span> == <span class="number">0</span>:</div><div class="line">        visualize(X_expanded[ind, :], y[ind], w, loss)</div><div class="line"></div><div class="line">    <span class="comment"># <span class="doctag">TODO:</span>&lt;your code here&gt;</span></div><div class="line">    dW = compute_grad(X_expanded[ind, :], y[ind], w)</div><div class="line">    g2 = dW**<span class="number">2</span></div><div class="line">    G = alpha*G+(<span class="number">1</span>-alpha)*g2</div><div class="line">    </div><div class="line">    w = w - eta*dW/np.sqrt(G+eps)</div><div class="line">    </div><div class="line">visualize(X, y, w, loss)</div><div class="line">plt.clf()</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[35]:</span></div><div class="line"></div><div class="line"><span class="comment"># use output of this cell to fill answer field </span></div><div class="line">ans_part6 = compute_loss(X_expanded, y, w)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[36]:</span></div><div class="line"></div><div class="line"><span class="comment">## GRADED PART, DO NOT CHANGE!</span></div><div class="line">grader.set_answer(<span class="string">"dLdHG"</span>, ans_part6)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[37]:</span></div><div class="line"></div><div class="line">grader.submit(COURSERA_EMAIL, COURSERA_TOKEN)</div><div class="line"></div><div class="line"></div><div class="line"><span class="comment"># In[ ]:</span></div></pre></td></tr></table></figure>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week"><a href="#Week" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-1"><a href="#Week-1" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-2"><a href="#Week-2" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-3"><a href="#Week-3" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-4"><a href="#Week-4" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="How-to-Win-a-Data-Science-Competition-Learn-from-Top-Kagglers"><a href="#How-to-Win-a-Data-Science-Competition-Learn-from-Top-Kagglers" class="headerlink" title="How to Win a Data Science Competition: Learn from Top Kagglers"></a>How to Win a Data Science Competition: Learn from Top Kagglers</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/competitive-data-science" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-5"><a href="#Week-5" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-6"><a href="#Week-6" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-7"><a href="#Week-7" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="Bayesian-Methods-for-Machine-Learning"><a href="#Bayesian-Methods-for-Machine-Learning" class="headerlink" title="Bayesian Methods for Machine Learning"></a>Bayesian Methods for Machine Learning</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/bayesian-methods-in-machine-learning" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-8"><a href="#Week-8" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-9"><a href="#Week-9" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-10"><a href="#Week-10" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="Introduction-to-Reinforcement-Learning"><a href="#Introduction-to-Reinforcement-Learning" class="headerlink" title="Introduction to Reinforcement Learning"></a>Introduction to Reinforcement Learning</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/introduction-to-reinforcement-learning" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-11"><a href="#Week-11" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-12"><a href="#Week-12" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-13"><a href="#Week-13" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="Deep-Learning-in-Computer-Vision"><a href="#Deep-Learning-in-Computer-Vision" class="headerlink" title="Deep Learning in Computer Vision"></a>Deep Learning in Computer Vision</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/deep-learning-in-computer-vision" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-14"><a href="#Week-14" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-15"><a href="#Week-15" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-16"><a href="#Week-16" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="Natural-Language-Processing"><a href="#Natural-Language-Processing" class="headerlink" title="Natural Language Processing"></a>Natural Language Processing</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/language-processing" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-17"><a href="#Week-17" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-18"><a href="#Week-18" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-19"><a href="#Week-19" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h1 id="Addressing-Large-Hadron-Collider-Challenges-by-Machine-Learning"><a href="#Addressing-Large-Hadron-Collider-Challenges-by-Machine-Learning" class="headerlink" title="Addressing Large Hadron Collider Challenges by Machine Learning"></a>Addressing Large Hadron Collider Challenges by Machine Learning</h1><div class="note primary"><p>Course can be found <a href="https://www.coursera.org/learn/hadron-collider-machine-learning" target="_blank" rel="external">here</a><br>Lecture slides can be found <a href="">here</a></p>
</div>
<h2 id="Week-20"><a href="#Week-20" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-21"><a href="#Week-21" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
<h2 id="Week-22"><a href="#Week-22" class="headerlink" title="Week"></a>Week</h2><div class="note primary"><p>primary</p>
</div>
<div class="note primary"><p>primary</p>
</div>
      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Coursera/" rel="tag"># Coursera</a>
          
            <a href="/tags/Machine-Learning/" rel="tag"># Machine Learning</a>
          
        </div>
      

      
        
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/09/26/Coursera PU 程序设计与算法 Specialization/" rel="next" title="Coursera PU 程序设计与算法 Specialization">
                <i class="fa fa-chevron-left"></i> Coursera PU 程序设计与算法 Specialization
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div id="disqus_thread">
        <noscript>
          Please enable JavaScript to view the
          <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a>
        </noscript>
      </div>
    
  </div>


        </div>
        
          
  
  
    <div class="sidebar-toggle">
      <div class="sidebar-toggle-line-wrap">
        <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
        <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
        <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
      </div>
    </div>
  

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          
            
          
        </ul>
      

      <section class="site-overview sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.png"
               alt="SSQ" />
          <p class="site-author-name" itemprop="name">SSQ</p>
           
              <p class="site-description motion-element" itemprop="description">Notebook for quick search</p>
          
        </div>
        <nav class="site-state motion-element">

          
            <div class="site-state-item site-state-posts">
              <a href="/archives">
                <span class="site-state-item-count">36</span>
                <span class="site-state-item-name">posts</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-categories">
              <a href="/categories/index.html">
                <span class="site-state-item-count">8</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            
            
            <div class="site-state-item site-state-tags">
              <a href="/tags/index.html">
                <span class="site-state-item-count">33</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/SSQ" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
          
        </div>

        
        

        
        

        


      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Deep-Learning"><span class="nav-number">1.</span> <span class="nav-text">Introduction to Deep Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-1-Introduction-to-optimization"><span class="nav-number">1.1.</span> <span class="nav-text">Week 1 Introduction to optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Course-intro"><span class="nav-number">1.1.1.</span> <span class="nav-text">Course intro</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Welcome-5-min"><span class="nav-number">1.1.1.1.</span> <span class="nav-text">Welcome!5 min</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Linear-model-as-the-simplest-neural-network"><span class="nav-number">1.1.2.</span> <span class="nav-text">Linear model as the simplest neural network</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Linear-regression-9-min"><span class="nav-number">1.1.2.1.</span> <span class="nav-text">Linear regression 9 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Linear-classification-10-min"><span class="nav-number">1.1.2.2.</span> <span class="nav-text">Linear classification 10 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient-descent-5-min"><span class="nav-number">1.1.2.3.</span> <span class="nav-text">Gradient descent 5 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Quiz-Linear-models-3-questions"><span class="nav-number">1.1.2.4.</span> <span class="nav-text">Quiz: Linear models 3 questions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Regularization-in-machine-learning"><span class="nav-number">1.1.3.</span> <span class="nav-text">Regularization in machine learning</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Overfitting-problem-and-model-validation-6-min"><span class="nav-number">1.1.3.1.</span> <span class="nav-text">Overfitting problem and model validation 6 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Model-regularization-5-min"><span class="nav-number">1.1.3.2.</span> <span class="nav-text">Model regularization 5 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Quiz-Overfitting-and-regularization-4-questions"><span class="nav-number">1.1.3.3.</span> <span class="nav-text">Quiz: Overfitting and regularization 4 questions</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Stochastic-methods-for-optimization"><span class="nav-number">1.1.4.</span> <span class="nav-text">Stochastic methods for optimization</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Stochastic-gradient-descent-5-min"><span class="nav-number">1.1.4.1.</span> <span class="nav-text">Stochastic gradient descent 5 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Gradient-descent-extensions-9-min"><span class="nav-number">1.1.4.2.</span> <span class="nav-text">Gradient descent extensions 9 min</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Linear-models-and-optimization"><span class="nav-number">1.1.4.3.</span> <span class="nav-text">Linear models and optimization</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Programming-Assignment-Linear-models-and-optimization-3h"><span class="nav-number">1.1.4.4.</span> <span class="nav-text">Programming Assignment: Linear models and optimization 3h</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week"><span class="nav-number">1.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-1"><span class="nav-number">1.3.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-2"><span class="nav-number">1.4.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-3"><span class="nav-number">1.5.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-4"><span class="nav-number">1.6.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#How-to-Win-a-Data-Science-Competition-Learn-from-Top-Kagglers"><span class="nav-number">2.</span> <span class="nav-text">How to Win a Data Science Competition: Learn from Top Kagglers</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-5"><span class="nav-number">2.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-6"><span class="nav-number">2.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-7"><span class="nav-number">2.3.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Bayesian-Methods-for-Machine-Learning"><span class="nav-number">3.</span> <span class="nav-text">Bayesian Methods for Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-8"><span class="nav-number">3.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-9"><span class="nav-number">3.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-10"><span class="nav-number">3.3.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Introduction-to-Reinforcement-Learning"><span class="nav-number">4.</span> <span class="nav-text">Introduction to Reinforcement Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-11"><span class="nav-number">4.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-12"><span class="nav-number">4.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-13"><span class="nav-number">4.3.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Deep-Learning-in-Computer-Vision"><span class="nav-number">5.</span> <span class="nav-text">Deep Learning in Computer Vision</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-14"><span class="nav-number">5.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-15"><span class="nav-number">5.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-16"><span class="nav-number">5.3.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Natural-Language-Processing"><span class="nav-number">6.</span> <span class="nav-text">Natural Language Processing</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-17"><span class="nav-number">6.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-18"><span class="nav-number">6.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-19"><span class="nav-number">6.3.</span> <span class="nav-text">Week</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Addressing-Large-Hadron-Collider-Challenges-by-Machine-Learning"><span class="nav-number">7.</span> <span class="nav-text">Addressing Large Hadron Collider Challenges by Machine Learning</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-20"><span class="nav-number">7.1.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-21"><span class="nav-number">7.2.</span> <span class="nav-text">Week</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Week-22"><span class="nav-number">7.3.</span> <span class="nav-text">Week</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">SSQ</span>
</div>


<div class="powered-by">
  Powered by <a class="theme-link" href="https://hexo.io">Hexo</a>
</div>

<div class="theme-info">
  Theme -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Mist
  </a>
</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
      
    </span>
  

  
    <span class="site-pv">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
      
    </span>
  
</div>


        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.1"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.1"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.1"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.1"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.1"></script>



  


  

    
      <script id="dsq-count-scr" src="https://SSQ.disqus.com/count.js" async></script>
    

    
      <script type="text/javascript">
        var disqus_config = function () {
          this.page.url = 'https://ssq.github.io/2017/11/19/Coursera HSE Advanced Machine Learning Specialization/';
          this.page.identifier = '2017/11/19/Coursera HSE Advanced Machine Learning Specialization/';
          this.page.title = 'Coursera HSE Advanced Machine Learning Specialization';
        };
        var d = document, s = d.createElement('script');
        s.src = 'https://SSQ.disqus.com/embed.js';
        s.setAttribute('data-timestamp', '' + +new Date());
        (d.head || d.body).appendChild(s);
      </script>
    

  




	





  





  








  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (search_path.endsWith("json")) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("MWlUL7cwf0gV4nd1BczDGmFm-gzGzoHsz", "YwuYEA1xBo0rm9hzIjUwOm2F");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
  


  

  

</body>
</html>
